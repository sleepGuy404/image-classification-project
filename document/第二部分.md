# 所有的数据都在文件夹work/zhongyaocai中

1. 数据集中的五类图片分别在：百合——baihe、党参——dangshen、枸杞——gouqi、槐花——huaihua、金银花——jinyinhua
2. 相关的列表文件分别为：validate_list.txt、test_list.txt、train_list.txt、label_list.txt
3. 文件夹中的temp.py文件是获取数据集中五类图片的相对路径以及标签。
4. 文件夹中的change_names.py文件是将从网上下载下来的图片重新命名，格式为：“种类+used_for_classification_序号.jpg”，图片名字对代码实现**没有任何影响**，目的是为了在分类之后更好的判断是否都分类正确。
5. 网上下载的50张图片的路径为：work/zhongyaocai/classification/total_images。在进行第八步后，五种图片的分类输出在文件夹classification中，有5个子文件夹，根据每张图片的标签将50张图片复制到不同的文件夹中。在程序运行前，这五个子文件夹里没有图片，程序运行后将50张图片复制到这5个文件夹中。
6. 由于数据集中每种中药材图片没有200张，便按照7：1：2的大致比例将每种中药材图片分为训练集、测试集以及验证集。
7. 提交的版本里的数据集是压缩包的格式，classification以文件夹的形式提交。
8. 解压到work文件夹中的指令:
~~~
unzip -oq /home/aistudio/zhongyaocai_ctr.zip -d /home/aistudio/work
~~~

# 迁移训练-使用finetune
## 一、简介

本任务为，将此前我们找到的准确率最高的预训练网络模型，改造为可以从上万张图片中，帮我们筛选为五分类的中草药模型。

——注意：前面的一到八，八个步骤使用自己的中草药数据集，介绍如何使用PaddleHub进行Fine-tune迁移训练图像分类。

我们的任务：

一.需要同学们稍微完善一到八八个步骤的代码（两处），使其可以根据选择的预训练模型进行迁移训练。

二.需要自己寻找50张图片，使用预训练模型进行分类识别。
最后，要么使用代码将图片放入不同文件夹，要么使用txt文本分别记录不同分类的中草药文件名，并记录正确率


请务必使用GPU环境, 因为下方的代码基于GPU环境.
请务必使用GPU环境, 因为下方的代码基于GPU环境.

![](https://ai-studio-static-online.cdn.bcebos.com/a14131369f3044f78eb96806b3983baa0b76f31f68b94e228c6de7d59a98fac5)

当前平台正在进行普遍赠送, 只要点击[此处表单](https://aistudio.baidu.com/aistudio/questionnaire?activityid=457)进行填写, 之后再度运行即可获赠. 

## 二、准备工作

首先导入必要的python包


```python
!pip install paddlehub==1.7.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
import paddle

```

    Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
    Requirement already satisfied: paddlehub==1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.7.0)
    Requirement already satisfied: gunicorn>=19.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (20.0.4)
    Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (1.21.0)
    Requirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (3.8.2)
    Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (3.14.0)
    Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (1.15.0)
    Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (1.1.5)
    Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (1.1.1)
    Requirement already satisfied: visualdl==2.0.0b1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (2.0.0b1)
    Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (0.26.0)
    Requirement already satisfied: cma>=2.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (2.7.0)
    Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (4.1.0)
    Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.7.0) (0.1.85)
    Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl==2.0.0b1->paddlehub==1.7.0) (7.1.2)
    Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl==2.0.0b1->paddlehub==1.7.0) (1.20.2)
    Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl==2.0.0b1->paddlehub==1.7.0) (4.1.1.26)
    Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl==2.0.0b1->paddlehub==1.7.0) (2.22.0)
    Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl==2.0.0b1->paddlehub==1.7.0) (1.0.0)
    Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.7.0) (0.6.1)
    Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.7.0) (2.6.0)
    Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.7.0) (0.23)
    Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.7.0) (2.2.0)
    Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.7.0) (0.16.0)
    Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.7.0) (2.10.1)
    Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.7.0) (7.0)
    Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.7.0) (1.1.0)
    Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl==2.0.0b1->paddlehub==1.7.0) (2019.3)
    Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl==2.0.0b1->paddlehub==1.7.0) (2.8.0)
    Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gunicorn>=19.10.0->paddlehub==1.7.0) (56.0.0)
    Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==1.7.0) (1.1.1)
    Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->flake8->paddlehub==1.7.0) (0.6.0)
    Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->flake8->paddlehub==1.7.0) (7.2.0)
    Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->paddlehub==1.7.0) (2.8.0)
    Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (1.4.10)
    Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (2.0.1)
    Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (0.10.0)
    Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (1.3.4)
    Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (5.1.2)
    Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (1.3.0)
    Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.7.0) (16.7.9)
    Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl==2.0.0b1->paddlehub==1.7.0) (2019.9.11)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl==2.0.0b1->paddlehub==1.7.0) (1.25.6)
    Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl==2.0.0b1->paddlehub==1.7.0) (2.8)
    Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl==2.0.0b1->paddlehub==1.7.0) (3.0.4)
    WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.
    You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.



```python
# -*- coding: utf8 -*-
import paddlehub as hub
%set_env CPU_NUM=1
```

    env: CPU_NUM=1


接下来我们要在PaddleHub中选择合适的预训练模型来Finetune。

请在此处选择前期任务准确率最高的模型




```python
import paddle
paddle.enable_static()
# 选择模型
# 此处代码为加载Hub提供的图像分类的预训练模型
module = hub.Module(name="googlenet_imagenet") 
```

    [2021-05-17 19:36:55,721] [    INFO] - Installing googlenet_imagenet module
    [2021-05-17 19:36:55,776] [    INFO] - Module googlenet_imagenet already installed in /home/aistudio/.paddlehub/modules/googlenet_imagenet


PaddleHub 还有着许多的图像分类预训练模型，更多信息参见[PaddleHub官方网站](https://www.paddlepaddle.org.cn/hub)

## 三、数据准备

此处的数据准备使用的是paddlehub提供的猫狗分类数据集，如果想要使用自定义的数据进行体验，需要自定义数据，请查看[适配自定义数据](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub%E9%80%82%E9%85%8D%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%88%90FineTune)


```python
# 此处演示的是直接用PaddleHub提供的数据集
# 同学们需要将此段代码更换为使用自己的代码
# dataset = hub.dataset.DogCat()

from paddlehub.dataset.base_cv_dataset import BaseCVDataset
   
class DemoDataset(BaseCVDataset):	
   def __init__(self):	
       # 数据集存放位置
       self.dataset_dir = "work/zhongyaocai"
       super(DemoDataset, self).__init__(
           base_path=self.dataset_dir,
           train_list_file="train_list.txt",
           validate_list_file="validate_list.txt",
           test_list_file="test_list.txt",
           # predict_file="predict_list.txt",
           label_list_file="label_list.txt",
           # label_list=["数据集所有类别"]
           )
dataset = DemoDataset()
```


如果想加载自定义数据集完成迁移学习，详细参见[自定义数据集](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub%E9%80%82%E9%85%8D%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%88%90FineTune)


## 四、生成Reader

接着生成一个图像分类的reader，reader负责将dataset的数据进行预处理，接着以特定格式组织并输入给模型进行训练。

当我们生成一个图像分类的reader时，需要指定输入图片的大小


```python
data_reader = hub.reader.ImageClassificationReader(
    image_width=module.get_expected_image_width(), #预期图片经过reader处理后的图像宽度
    image_height=module.get_expected_image_height(),#预期图片经过reader处理后的图像高度
    images_mean=module.get_pretrained_images_mean(),#进行图片标准化处理时所减均值。默认为None
    images_std=module.get_pretrained_images_std(), #进行图片标准化处理时所除标准差。默认为None
    dataset=dataset)
```

    [2021-05-17 19:42:11,968] [    INFO] - Dataset label map = {'baihe 0': 0, 'dangshen 1': 1, 'gouqi 2': 2, 'huaihua 3': 3, 'jinyinhua 4': 4}


## 五、选择运行时配置

在进行Finetune前，我们可以设置一些运行时的配置，例如如下代码中的配置，表示：

* `use_cuda`：设置为False表示使用CPU进行训练。如果您本机支持GPU，且安装的是GPU版本的PaddlePaddle，我们建议您将这个选项设置为True；

* `epoch`：要求Finetune的任务只遍历1次训练集；

* `batch_size`：每次训练的时候，给模型输入的每批数据大小为32，模型训练时能够并行处理批数据，因此batch_size越大，训练的效率越高，但是同时带来了内存的负荷，过大的batch_size可能导致内存不足而无法训练，因此选择一个合适的batch_size是很重要的一步；

* `log_interval`：每隔10 step打印一次训练日志；

* `eval_interval`：每隔50 step在验证集上进行一次性能评估；

* `checkpoint_dir`：将训练的参数和数据保存到cv_finetune_turtorial_demo目录中；

* `strategy`：使用DefaultFinetuneStrategy策略进行finetune；

更多运行配置，请查看[RunConfig](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-RunConfig)

同时PaddleHub提供了许多优化策略，如`AdamWeightDecayStrategy`、`ULMFiTStrategy`、`DefaultFinetuneStrategy`等，详细信息参见[策略](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Strategy)


```python
config = hub.RunConfig(
    use_cuda=True,                                            #是否使用GPU训练，默认为False；
    num_epoch=20,                                              #Fine-tune的轮数；使用4轮，直到训练准确率达到90%多
    checkpoint_dir="cv_finetune_turtorial_demo",              #模型checkpoint保存路径, 若用户没有指定，程序会自动生成；
    batch_size=32,                                            #训练的批大小，如果使用GPU，请根据实际情况调整batch_size；
    eval_interval=50,                                         #模型评估的间隔，默认每100个step评估一次验证集；
    strategy=hub.finetune.strategy.DefaultFinetuneStrategy()) #Fine-tune优化策略；
```

    [2021-05-17 20:37:26,656] [    INFO] - Checkpoint dir: cv_finetune_turtorial_demo


## 六、组建Finetune Task

有了合适的预训练模型和准备要迁移的数据集后，我们开始组建一个Task。

由于猫狗分类是一个二分类的任务，而我们下载的分类module是在ImageNet数据集上训练的千分类模型，所以我们需要对模型进行简单的微调，把模型改造为一个二分类模型：

1. 获取module的上下文环境，包括输入和输出的变量，以及Paddle Program；
2. 从输出变量中找到特征图提取层feature_map；
3. 在feature_map后面接入一个全连接层，生成Task；


```python
#获取module的上下文信息包括输入、输出变量以及paddle program
input_dict, output_dict, program = module.context(trainable=True) 

#待传入图片格式
img = input_dict["image"]  

#从预训练模型的输出变量中找到最后一层特征图，提取最后一层的feature_map
feature_map = output_dict["feature_map"]   

#待传入的变量名字列表
feed_list = [img.name]

task = hub.ImageClassifierTask(
    data_reader=data_reader,        #提供数据的Reader
    feed_list=feed_list,            #待feed变量的名字列表
    feature=feature_map,            #输入的特征矩阵
    num_classes=dataset.num_labels, #分类任务的类别数量，此处来自于数据集的num_labels
    config=config)                  #运行配置
```

    [2021-05-17 20:37:28,902] [    INFO] - 59 pretrained paramaters loaded by PaddleHub


如果想改变迁移任务组网，详细参见[自定义迁移任务](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub:-%E8%87%AA%E5%AE%9A%E4%B9%89Task)

## 七、开始Finetune

我们选择`finetune_and_eval`接口来进行模型训练，这个接口在finetune的过程中，会周期性的进行模型效果的评估，以便我们了解整个训练过程的性能变化。


```python
run_states = task.finetune_and_eval() #通过众多finetune API中的finetune_and_eval接口，可以一边训练网络，一边打印结果
```

    [2021-05-17 20:37:40,121] [    INFO] - Try loading checkpoint from cv_finetune_turtorial_demo/ckpt.meta



    ---------------------------------------------------------------------------

    OSError                                   Traceback (most recent call last)

    <ipython-input-71-a0c4e8399ce4> in <module>
    ----> 1 run_states = task.finetune_and_eval() #通过众多finetune API中的finetune_and_eval接口，可以一边训练网络，一边打印结果
    

    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in finetune_and_eval(self)
        866 
        867     def finetune_and_eval(self):
    --> 868         return self.finetune(do_eval=True)
        869 
        870     def finetune(self, do_eval=False):


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in finetune(self, do_eval)
        881         # Start to finetune
        882         with self.phase_guard(phase="train"):
    --> 883             self.init_if_necessary()
        884             self._finetune_start_event()
        885             run_states = []


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in init_if_necessary(self)
        365     def init_if_necessary(self):
        366         if not self.is_checkpoint_loaded:
    --> 367             if not self.load_checkpoint():
        368                 self.exe.run(self._base_startup_program)
        369             self.is_checkpoint_loaded = True


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in load_checkpoint(self)
        832             self.config.checkpoint_dir,
        833             self.exe,
    --> 834             main_program=self.main_program)
        835         # Revise max_train_steps when incremental training
        836         if is_load_successful:


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/checkpoint.py in load_checkpoint(checkpoint_dir, exe, main_program)
         45     if ckpt.latest_model_dir:
         46         fluid.io.load_vars(
    ---> 47             exe, ckpt.latest_model_dir, main_program, predicate=if_exist)
         48 
         49         # Compatible with older versions without best_score in checkpoint_pb2


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)
        795             main_program=main_program,
        796             vars=list(filter(predicate, main_program.list_vars())),
    --> 797             filename=filename)
        798     else:
        799         load_prog = Program()


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)
        912                     'model_from_memory': vars_from_memory
        913                 })
    --> 914         executor.run(load_prog)
        915 
        916         # check var shape


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)
       1108                 return_merged=return_merged)
       1109         except Exception as e:
    -> 1110             six.reraise(*sys.exc_info())
       1111 
       1112     def _run_impl(self, program, feed, fetch_list, feed_var_name,


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)
        701             if value.__traceback__ is not tb:
        702                 raise value.with_traceback(tb)
    --> 703             raise value
        704         finally:
        705             value = None


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)
       1106                 use_program_cache=use_program_cache,
       1107                 use_prune=use_prune,
    -> 1108                 return_merged=return_merged)
       1109         except Exception as e:
       1110             six.reraise(*sys.exc_info())


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py in _run_impl(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)
       1236                 scope=scope,
       1237                 return_numpy=return_numpy,
    -> 1238                 use_program_cache=use_program_cache)
       1239 
       1240         program._compile(scope, self.place)


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py in _run_program(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)
       1326         if not use_program_cache:
       1327             self._default_executor.run(program.desc, scope, 0, True, True,
    -> 1328                                        [fetch_var_name])
       1329         else:
       1330             self._default_executor.run_prepared_ctx(ctx, scope, False, False,


    OSError: (External)  Cuda error(2), out of memory.
      [Advise: The API call failed because it was unable to allocate enough memory to perform the requested operation. ] (at /paddle/paddle/fluid/platform/stream/cuda_stream.cc:36)



## 八、使用模型进行预测

当Finetune完成后，我们使用模型来进行预测，先通过以下命令来获取测试的图片

`注意`：填入测试图片路径后方可开始测试

预测代码如下：


```python
import numpy as np
import random
import os
import shutil

# 获取所有图片的路径
def get_file_names():
    filenames = os.listdir("work/zhongyaocai/classification/total_images/")
    random.shuffle(filenames)
    new_filenames = []
    for filename in filenames:
        new_filename = "work/zhongyaocai/classification/total_images/"+filename
        new_filenames.append(new_filename)
    return new_filenames

# 复制文件到指定的文件夹中
def copyfile(srcfile, dstfile):
    if not os.path.isfile(srcfile):
        print("%s not exist!" % (srcfile))
    else:
        fpath, fname = os.path.split(dstfile)  # 分离文件名和路径
        if not os.path.exists(fpath):
            os.makedirs(fpath)  # 创建路径
        shutil.copyfile(srcfile, dstfile)  # 复制文件

def accuracy_result(str_list,result):
    filename_list = str_list[-1].split('_')
    identifying_result_list  =result.split(' ')
    result_list = []
    result_list.append(filename_list[0])
    result_list.append(identifying_result_list[0])
    return result_list
    


data = get_file_names()       #此处传入需要识别的照片地址
# print(data)  #测试使用
label_map = dataset.label_dict()  # 结果为{0: 'baihe 0', 1: 'dangshen 1', 2: 'gouqi 2', 3: 'huaihua 3', 4: 'jinyinhua 4'}
index = 0
label_folders = {}   # 创建一个字典，键为标签（0到4），值为对应的文件夹的名字
for label,value in label_map.items():
    str_list = value.split(' ')
    label_folders[label] = str_list[0]



classify_images_dir = "work/zhongyaocai/classification/"

# get classification result
run_states = task.predict(data=data) #进行预测
results = [run_state.run_results for run_state in run_states] #得到用新模型预测test照片的结果

accuracy_dict = {} # 创建一个字典，用于存储原图像的标签和识别返回的标签，最后用于绘制正确率的图像

for batch_result in results:
    # get predict index
    batch_result = np.argmax(batch_result, axis=2)[0]
    for result in batch_result:
        index += 1
        # 将图片复制到识别后对应的文件夹中,首先获取文件名，然后创建复制后的路径
        str_list = data[index-1].split('/')
        destFile = classify_images_dir + label_folders[result] + '/' + str_list[-1]
        sourceFile = data[index -1]
        copyfile(sourceFile, destFile)
        result = label_map[result]
        accuracy_dict[str_list[-1]]=accuracy_result(str_list,result)
        print("input %i is %s, and the predict result is %s" %
              (index, data[index - 1], result))

print(accuracy_dict)
```

    [2021-05-17 19:42:24,079] [    INFO] - PaddleHub predict start
    [2021-05-17 19:42:24,080] [    INFO] - Load the best model from cv_finetune_turtorial_demo/best_model
    [2021-05-17 19:42:27,633] [    INFO] - PaddleHub predict finished.


    input 1 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_3.jpg, and the predict result is huaihua 3
    input 2 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_3.jpg, and the predict result is dangshen 1
    input 3 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_4.jpg, and the predict result is jinyinhua 4
    input 4 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_1.jpg, and the predict result is baihe 0
    input 5 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_6.jpg, and the predict result is huaihua 3
    input 6 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_1.jpg, and the predict result is huaihua 3
    input 7 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_4.jpg, and the predict result is gouqi 2
    input 8 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_2.jpg, and the predict result is huaihua 3
    input 9 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_9.jpg, and the predict result is dangshen 1
    input 10 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_2.jpg, and the predict result is gouqi 2
    input 11 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_5.jpg, and the predict result is gouqi 2
    input 12 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_9.jpg, and the predict result is gouqi 2
    input 13 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_1.jpg, and the predict result is dangshen 1
    input 14 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_6.jpg, and the predict result is jinyinhua 4
    input 15 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_10.jpg, and the predict result is baihe 0
    input 16 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_7.jpg, and the predict result is gouqi 2
    input 17 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_4.jpg, and the predict result is dangshen 1
    input 18 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_3.jpg, and the predict result is gouqi 2
    input 19 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_2.jpg, and the predict result is jinyinhua 4
    input 20 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_6.jpg, and the predict result is gouqi 2
    input 21 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_7.jpg, and the predict result is dangshen 1
    input 22 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_5.jpg, and the predict result is baihe 0
    input 23 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_3.jpg, and the predict result is jinyinhua 4
    input 24 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_4.jpg, and the predict result is baihe 0
    input 25 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_10.jpg, and the predict result is jinyinhua 4
    input 26 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_9.jpg, and the predict result is huaihua 3
    input 27 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_2.jpg, and the predict result is huaihua 3
    input 28 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_6.jpg, and the predict result is baihe 0
    input 29 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_9.jpg, and the predict result is huaihua 3
    input 30 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_8.jpg, and the predict result is jinyinhua 4
    input 31 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_5.jpg, and the predict result is dangshen 1
    input 32 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_8.jpg, and the predict result is gouqi 2
    input 33 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_8.jpg, and the predict result is baihe 0
    input 34 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_10.jpg, and the predict result is dangshen 1
    input 35 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_1.jpg, and the predict result is huaihua 3
    input 36 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_8.jpg, and the predict result is dangshen 1
    input 37 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_7.jpg, and the predict result is jinyinhua 4
    input 38 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_1.jpg, and the predict result is gouqi 2
    input 39 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_7.jpg, and the predict result is huaihua 3
    input 40 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_8.jpg, and the predict result is huaihua 3
    input 41 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_7.jpg, and the predict result is baihe 0
    input 42 is work/zhongyaocai/classification/total_images/jinyinhua_used_for_classification_5.jpg, and the predict result is jinyinhua 4
    input 43 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_5.jpg, and the predict result is huaihua 3
    input 44 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_4.jpg, and the predict result is huaihua 3
    input 45 is work/zhongyaocai/classification/total_images/gouqi_used_for_classification_10.jpg, and the predict result is gouqi 2
    input 46 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_3.jpg, and the predict result is baihe 0
    input 47 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_9.jpg, and the predict result is baihe 0
    input 48 is work/zhongyaocai/classification/total_images/dangshen_used_for_classification_6.jpg, and the predict result is dangshen 1
    input 49 is work/zhongyaocai/classification/total_images/huaihua_used_for_classification_10.jpg, and the predict result is huaihua 3
    input 50 is work/zhongyaocai/classification/total_images/baihe_used_for_classification_2.jpg, and the predict result is baihe 0
    {'huaihua_used_for_classification_3.jpg': ['huaihua', 'huaihua'], 'dangshen_used_for_classification_3.jpg': ['dangshen', 'dangshen'], 'jinyinhua_used_for_classification_4.jpg': ['jinyinhua', 'jinyinhua'], 'baihe_used_for_classification_1.jpg': ['baihe', 'baihe'], 'huaihua_used_for_classification_6.jpg': ['huaihua', 'huaihua'], 'jinyinhua_used_for_classification_1.jpg': ['jinyinhua', 'huaihua'], 'gouqi_used_for_classification_4.jpg': ['gouqi', 'gouqi'], 'dangshen_used_for_classification_2.jpg': ['dangshen', 'huaihua'], 'dangshen_used_for_classification_9.jpg': ['dangshen', 'dangshen'], 'gouqi_used_for_classification_2.jpg': ['gouqi', 'gouqi'], 'gouqi_used_for_classification_5.jpg': ['gouqi', 'gouqi'], 'gouqi_used_for_classification_9.jpg': ['gouqi', 'gouqi'], 'dangshen_used_for_classification_1.jpg': ['dangshen', 'dangshen'], 'jinyinhua_used_for_classification_6.jpg': ['jinyinhua', 'jinyinhua'], 'baihe_used_for_classification_10.jpg': ['baihe', 'baihe'], 'gouqi_used_for_classification_7.jpg': ['gouqi', 'gouqi'], 'dangshen_used_for_classification_4.jpg': ['dangshen', 'dangshen'], 'gouqi_used_for_classification_3.jpg': ['gouqi', 'gouqi'], 'jinyinhua_used_for_classification_2.jpg': ['jinyinhua', 'jinyinhua'], 'gouqi_used_for_classification_6.jpg': ['gouqi', 'gouqi'], 'dangshen_used_for_classification_7.jpg': ['dangshen', 'dangshen'], 'baihe_used_for_classification_5.jpg': ['baihe', 'baihe'], 'jinyinhua_used_for_classification_3.jpg': ['jinyinhua', 'jinyinhua'], 'baihe_used_for_classification_4.jpg': ['baihe', 'baihe'], 'jinyinhua_used_for_classification_10.jpg': ['jinyinhua', 'jinyinhua'], 'jinyinhua_used_for_classification_9.jpg': ['jinyinhua', 'huaihua'], 'huaihua_used_for_classification_2.jpg': ['huaihua', 'huaihua'], 'baihe_used_for_classification_6.jpg': ['baihe', 'baihe'], 'huaihua_used_for_classification_9.jpg': ['huaihua', 'huaihua'], 'jinyinhua_used_for_classification_8.jpg': ['jinyinhua', 'jinyinhua'], 'dangshen_used_for_classification_5.jpg': ['dangshen', 'dangshen'], 'gouqi_used_for_classification_8.jpg': ['gouqi', 'gouqi'], 'baihe_used_for_classification_8.jpg': ['baihe', 'baihe'], 'dangshen_used_for_classification_10.jpg': ['dangshen', 'dangshen'], 'huaihua_used_for_classification_1.jpg': ['huaihua', 'huaihua'], 'dangshen_used_for_classification_8.jpg': ['dangshen', 'dangshen'], 'jinyinhua_used_for_classification_7.jpg': ['jinyinhua', 'jinyinhua'], 'gouqi_used_for_classification_1.jpg': ['gouqi', 'gouqi'], 'huaihua_used_for_classification_7.jpg': ['huaihua', 'huaihua'], 'huaihua_used_for_classification_8.jpg': ['huaihua', 'huaihua'], 'baihe_used_for_classification_7.jpg': ['baihe', 'baihe'], 'jinyinhua_used_for_classification_5.jpg': ['jinyinhua', 'jinyinhua'], 'huaihua_used_for_classification_5.jpg': ['huaihua', 'huaihua'], 'huaihua_used_for_classification_4.jpg': ['huaihua', 'huaihua'], 'gouqi_used_for_classification_10.jpg': ['gouqi', 'gouqi'], 'baihe_used_for_classification_3.jpg': ['baihe', 'baihe'], 'baihe_used_for_classification_9.jpg': ['baihe', 'baihe'], 'dangshen_used_for_classification_6.jpg': ['dangshen', 'dangshen'], 'huaihua_used_for_classification_10.jpg': ['huaihua', 'huaihua'], 'baihe_used_for_classification_2.jpg': ['baihe', 'baihe']}


## 九、自己寻找50张中草药图片（还是我们5种分类的图片，但是不能使用我们训练图片），然后对50张中草药图片进行分类，并记录准确率。


```python
correct_number = 0
wrong_dict={}
for key, value in accuracy_dict.items():
    if value[0]==value[1]:
        correct_number +=1
    else:
        wrong_dict[key]=value

accuracy = correct_number*100/len(accuracy_dict)
print(f"识别准确率为：{accuracy}%\n")
print("识别错误的图片：")
for key,value in wrong_dict.items():
    print(f"\t图片{key}，被识别为{value[1]}类")
```

    识别准确率为：94.0%
    
    识别错误的图片：
    	图片jinyinhua_used_for_classification_1.jpg，被识别为huaihua类
    	图片dangshen_used_for_classification_2.jpg，被识别为huaihua类
    	图片jinyinhua_used_for_classification_9.jpg，被识别为huaihua类



```python
#此处开始进行分类
#在上方第八步中分类
#文档说明在最上面
```
